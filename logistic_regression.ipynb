{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>43500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>107500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>863</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>59000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>800</td>\n",
       "      <td>Female</td>\n",
       "      <td>47</td>\n",
       "      <td>23500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>407</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>138500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>299</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>134000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>687</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>73500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User ID  Gender  Age  AnnualSalary  Purchased\n",
       "0        385    Male   35         20000          0\n",
       "1        681    Male   40         43500          0\n",
       "2        353    Male   49         74000          0\n",
       "3        895    Male   40        107500          1\n",
       "4        661    Male   25         79000          0\n",
       "..       ...     ...  ...           ...        ...\n",
       "995      863    Male   38         59000          0\n",
       "996      800  Female   47         23500          0\n",
       "997      407  Female   28        138500          1\n",
       "998      299  Female   48        134000          1\n",
       "999      687  Female   44         73500          0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('car_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>-1</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681</td>\n",
       "      <td>-1</td>\n",
       "      <td>40</td>\n",
       "      <td>43500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>-1</td>\n",
       "      <td>49</td>\n",
       "      <td>74000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>-1</td>\n",
       "      <td>40</td>\n",
       "      <td>107500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "      <td>79000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>863</td>\n",
       "      <td>-1</td>\n",
       "      <td>38</td>\n",
       "      <td>59000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>23500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>407</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>138500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>134000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>687</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>73500</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User ID  Gender  Age  AnnualSalary  Purchased\n",
       "0        385      -1   35         20000         -1\n",
       "1        681      -1   40         43500         -1\n",
       "2        353      -1   49         74000         -1\n",
       "3        895      -1   40        107500          1\n",
       "4        661      -1   25         79000         -1\n",
       "..       ...     ...  ...           ...        ...\n",
       "995      863      -1   38         59000         -1\n",
       "996      800       1   47         23500         -1\n",
       "997      407       1   28        138500          1\n",
       "998      299       1   48        134000          1\n",
       "999      687       1   44         73500         -1\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the column value in Purchase, 0 to -1\n",
    "df['Purchased'] = df['Purchased'].map({0:-1, 1:1})\n",
    "df['Gender'] = df['Gender'].map({'Male': -1, 'Female': 1 })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def loss(beta, X, y, lam, p):\n",
    "    # Logistic loss with L_p regularization\n",
    "    logistic_loss = np.mean(np.log(1 + np.exp(-y * np.dot(X, beta))))\n",
    "    reg_loss = lam * np.linalg.norm(beta, p)\n",
    "    return logistic_loss + reg_loss\n",
    "\n",
    "def gradient(beta, X, y, lam, p):\n",
    "    # Gradient of logistic loss\n",
    "    logistic_grad = np.dot(X.T, -y / (1 + np.exp(y * np.dot(X, beta))))\n",
    "    # Gradient of regularization term\n",
    "    if p == 1:\n",
    "        reg_grad = lam * np.sign(beta)\n",
    "    else:\n",
    "        norm_beta_p_minus_1 = np.power(np.abs(beta), p - 1)\n",
    "        reg_grad = lam * np.multiply(np.sign(beta), norm_beta_p_minus_1)\n",
    "        reg_grad /= np.power(np.linalg.norm(beta, p), p-1)\n",
    "    \n",
    "    return logistic_grad + reg_grad\n",
    "\n",
    "def logistic_regression(X, y, lam, p):\n",
    "    # Initialize beta with zeros or logistic regression coefficients as a starting point\n",
    "    beta_init = LogisticRegression().fit(X, y).coef_[0]   \n",
    "    # Define the objective function (loss) to minimize\n",
    "    obj_func = lambda beta: loss(beta, X, y, lam, p)\n",
    "    # Define the gradient of the objective function\n",
    "    obj_grad = lambda beta: gradient(beta, X, y, lam, p)\n",
    "    # Use scipy.optimize.minimize with the 'BFGS' method, providing the gradient\n",
    "    result = minimize(fun=obj_func, x0=beta_init, jac=obj_grad, method='BFGS')\n",
    "    print(result.x)\n",
    "    return result.x\n",
    "\n",
    "def predict(X, y, beta):\n",
    "    # y_one is the probability of class 1\n",
    "    y_one = np.exp(np.dot(X, beta)) / (1 + np.exp(np.dot(X, beta)))\n",
    "    # y_pred is the predicted class\n",
    "    y_pred = np.sign(y_one - 0.5)\n",
    "\n",
    "    # check the correct accuracy \n",
    "    accuracy = np.mean(y == y_pred)\n",
    "    return accuracy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, logistic regression is to return the beta after fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix (X) shape: (1000, 5)\n",
      "Target variable (y) shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "def generate_logistic_regression_data(n_samples, n_features, beta_true):\n",
    "    \"\"\"\n",
    "    Generate data for logistic regression.\n",
    "    \n",
    "    Parameters:\n",
    "    - n_samples: int, the number of samples.\n",
    "    - n_features: int, the number of features.\n",
    "    - beta_true: array-like, the true coefficients, including the intercept as the first element.\n",
    "    \n",
    "    Returns:\n",
    "    - X: array, shape (n_samples, n_features), the feature matrix.\n",
    "    - y: array, shape (n_samples,), the target variable with values in {-1, 1}.\n",
    "    \"\"\"\n",
    "    # Generate feature matrix X with an intercept (bias) term\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    X = np.hstack((np.ones((n_samples, 1)), X))  # Adding intercept term\n",
    "    \n",
    "    # Compute logits (linear combination + intercept)\n",
    "    logits = np.dot(X, beta_true)\n",
    "    \n",
    "    # Apply logistic function to get probabilities\n",
    "    probabilities = 1 / (1 + np.exp(-logits))\n",
    "    \n",
    "    # Generate binary outcomes based on probabilities\n",
    "    y = np.where(probabilities >= 0.5, 1, -1)\n",
    "\n",
    "    # add noise to the data\n",
    "    X = X + np.random.normal(0, 10, X.shape)\n",
    "    # after y from 1 to -1 or -1 to 1 by 10% of the data\n",
    "    for i in range(int(n_samples * 0.1)):\n",
    "        if y[i] == 1:\n",
    "            y[i] = -1\n",
    "        else:\n",
    "            y[i] = 1\n",
    "    \n",
    "    return X[:, 1:], y  # Return X without intercept term and y\n",
    "\n",
    "# Example usage\n",
    "n_samples = 1000\n",
    "n_features = 5\n",
    "beta_true = np.array([0.5, -1, 2, 0.5, -0.25, 0.75])  # Including intercept\n",
    "\n",
    "X, y = generate_logistic_regression_data(n_samples, n_features, beta_true)\n",
    "\n",
    "print(\"Feature matrix (X) shape:\", X.shape)\n",
    "print(\"Target variable (y) shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01271893  0.00468129  0.00280432 -0.00074565 -0.00191272]\n",
      "[-0.01257002  0.00472616  0.00290424 -0.0005915  -0.00182738]\n",
      "[-0.01253636  0.00469647  0.00282714 -0.00068934 -0.00189047]\n",
      "[-0.01245492  0.00469751  0.00282311 -0.00068419 -0.0018944 ]\n",
      "[-0.01237216  0.00469928  0.0028135  -0.00067717 -0.00189383]\n",
      "[-0.01229101  0.00469989  0.00281104 -0.00067254 -0.00189899]\n",
      "{5: [0.518, 0.518, 0.516, 0.516, 0.516, 0.516]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.516"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "p_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "lam_values = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "'''\n",
    "beta_test = logistic_regression(X_train, y_train, lam=0.1, p=1)\n",
    "print(beta_test)\n",
    "\n",
    "accuracy = predict(X_test, y_test, beta_test)\n",
    "print(accuracy)\n",
    "'''\n",
    "\n",
    "# for each p-values, and lam_values, store the accuracy in dictionary\n",
    "accuracy_dict = {}\n",
    "\n",
    "p = p_values[4]\n",
    "accuracy_dict[p] = []\n",
    "for lam in lam_values:\n",
    "    beta = logistic_regression(X_train, y_train, lam, p)\n",
    "    accuracy = predict(X_test, y_test, beta)\n",
    "    accuracy_dict[p].append(accuracy)\n",
    "\n",
    "print(accuracy_dict)\n",
    "\n",
    "\n",
    "plain_beta = LogisticRegression().fit(X_train, y_train).coef_[0]\n",
    "plain_accuracy = predict(X_test, y_test, plain_beta)\n",
    "plain_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qids-2023-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
